# Malware-Analysis-Through-Visualization-of-The-Convolutional-Neural-Network
## Motivation
Malware is a huge threat to almost everything that is Online. They are hard to detect and require a huge amount of effort to prevent them. We propose a method that uses CNN(Convolutional Neural Network) to extract the features and behaviours of malicious android apps. Those features can then be used to train different models to get a good accuracy of classifying maleware and benign applications.

## Model's Architecture
The layer structure of the Convolutional Neural Network that we are using is given as follow.
<p align="center">
  <img src="Images/CNN Architecture.png?raw=true" alt="CNN Network Architecture"/>
</p>

## Observation
Here we use 6 Layers in the Model. All these layers are being trained on the **byte-code** images of android's apk.
* We first use a Convolution layer that gives us an output shape of (206 x 206 x 32).
* A max pooling layer giving us (103 x 103 x 32).
* For the problem of vanishing gradient, a dropout layer is used with a threshold of 0.2.
* The output is then flattened out using the using the flatten layer.
* We then have a dense layer with 128 neurons. Relu activation is used.
* The output layer has 2 neurons as this is a binary classification. Softmax activation is used.
* A total of 43,455,682 perameters are available to be trained and will contribute in the classification of malignent or benign files.

## Dataset
The dataset was generated by downloading malicious and benign apks from Google's Play Store and Andro Zoo (100% Malicious Market place for apks).

* The byte-code of these apks are extracted. 16bit binary code that runs on Delvik.
<p align="center">
  <img src="Images/byte-code.png?raw=true" alt="Byte-Code of apk"/>
</p>

* This bytecode is then reshaped in 2 dimensions to form images.
<p align="center">
  <img src="Images/100.png?raw=true" alt="Byte-Code Image"/>
</p>

## Methodology
* This is a binary classification problem so we have 2 labels. **0** Represents the **Benign apks** and **1** Represents the **Malicious apks**.

When the model is trained, we then visualize the activations on all the layers. As we are using 32 channels, there will be 32 activations per layer. 5 Layers are used from which 3 are visualised, 1 is voting and the last one is output layer.

An image that the neural network has never seen before is feed to the network after the training procedure. We can see the activations, that image is causing in the network. Basically those are the features, the CNN is looking at right that moment when seeing a never-seen-before image.

## Visualization
The layers showing different activation based on that never-seen-before image.
<p align="center">
  <img src="Images/layer_Visualization.png?raw=true" alt="Layer Activations"/>
</p>

## Useage
### Requirments
* Python
* Anaconda
* Tensorflow Backend (CPU or GPU)
* Keras

### Discription
The project folder contrains the dataset in the form of numpy lists. Two types of list are present. One contains the images and the other contains corresponding labels. There is an image for testing the activations. The above mentioned never-seen-before image.
